{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs0VQK0Nc-Rj"
   },
   "source": [
    "## Очистка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RZ5vZFWEctos",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "96706390-f844-4575-b8e2-d5190f7b7da0"
   },
   "outputs": [],
   "source": [
    "# ! pip install datasets --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZpmZlcN-ctcr"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных и первичная отладка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIwVP7ivctaA",
    "outputId": "94389ce1-d1d1-45f4-e513-d9591668b2c9"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"d0rj/geo-reviews-dataset-2023\")\n",
    "work_data = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POlHzknictXQ"
   },
   "outputs": [],
   "source": [
    "work_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSjqUpZTctUg"
   },
   "outputs": [],
   "source": [
    "work_data = work_data.dropna(subset=['text', 'name_ru', 'rating'])\n",
    "work_data = work_data.drop_duplicates(subset=['text']).reset_index(drop=True)\n",
    "work_data['text'] = work_data['text'].str.replace('\\\\n', ' ')\n",
    "\n",
    "work_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_hXfg_kctR9"
   },
   "outputs": [],
   "source": [
    "work_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LxJiyZT64sc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "''' Очистка текста от лишних элементов '''\n",
    "def clean_review_text(text: str) -> str:\n",
    "    text = text.lower()                         # <-- приводим к нижнему регистру\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)         # <-- удаляем HTML-теги\n",
    "    text = re.sub(r\"[^\\w\\s,.!?()]+\", \"\", text)  # <-- удаляем спецсимволы, кроме пунктуации и скобок\n",
    "    text = re.sub(r\"\\)\\)+\", \" \", text)          # <-- заменяем смайлики вида \"))\" на пробел\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    # <-- убираем лишние пробелы\n",
    "    text = re.sub(r\"[\\n\\r]+\", \" \", text)        # <-- заменяем переносы строк на пробелы\n",
    "    return text\n",
    "\n",
    "''' Очистка столбца рубрик для разделения по тематикам '''\n",
    "def clean_rubrics(rubrics_: str) -> str:\n",
    "    return rubrics_.lower().strip()\n",
    "\n",
    "''' Очистка наименования объекта '''\n",
    "def clean_name_ru(name_ru: str) -> str:\n",
    "    return name_ru.lower().strip()\n",
    "\n",
    "''' Очистка адреса '''\n",
    "def clean_address(address: str) -> str:\n",
    "    address = address.strip()\n",
    "    return re.sub(r\"\\s+\", \" \", address)\n",
    "\n",
    "\n",
    "# Применяем ко всем столбцам в датасете очистку\n",
    "work_data['text'] = work_data['text'].apply(clean_review_text)\n",
    "work_data['rubrics'] = work_data['rubrics'].apply(clean_rubrics)\n",
    "work_data['name_ru'] = work_data['name_ru'].apply(clean_name_ru)\n",
    "work_data['address'] = work_data['address'].apply(clean_address)\n",
    "\n",
    "# Преобразование рейтинга в числовой формат\n",
    "work_data['rating'] = work_data['rating'].astype(float)\n",
    "\n",
    "# Удаление строк с пропущенными значениями\n",
    "work_data.dropna(subset=['address', 'name_ru', 'rubrics', 'rating', 'text'], inplace=True)\n",
    "work_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ACDhH98073Ht",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "work_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование данных, интеграция с поиском ключевых слов (выбрано в качестве шаблона 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "33Za3O67HwSS"
   },
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Загружаем стоп-слова\n",
    "nltk.download('stopwords', quiet=True)\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "\n",
    "# Функция для извлечения трех ключевых слов\n",
    "def extract_keywords(text):\n",
    "    text = text.strip()\n",
    "    if not text:            # <-- проверка на пустую строку\n",
    "        return ''\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words=russian_stopwords, max_features=3)\n",
    "\n",
    "    try:\n",
    "        X = vectorizer.fit_transform([text])\n",
    "        # Извлекаем ключевые слова\n",
    "        keywords = vectorizer.get_feature_names_out()\n",
    "        return ', '.join(keywords)\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Tx19FGdWHwUk"
   },
   "outputs": [],
   "source": [
    "work_data['key_words'] = work_data['text'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Is0GxZS6RdIm"
   },
   "outputs": [],
   "source": [
    "work_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAQPHF8oRhgT"
   },
   "outputs": [],
   "source": [
    "# Удаление данных без ключевых слов\n",
    "weird_data = work_data[work_data['key_words']=='']\n",
    "weird_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR8K_DMnR33a"
   },
   "outputs": [],
   "source": [
    "work_data = work_data[work_data['key_words']!='']\n",
    "work_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO9FRF0FctHP"
   },
   "outputs": [],
   "source": [
    "work_data.to_csv('work_data.csv', index=False)\n",
    "print(\"Данные успешно очищены и сохранены в 'work_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9c0be9e-8fc2-4fa4-911c-8f73b537e14c",
     "showTitle": false,
     "title": ""
    },
    "id": "7lIRmY2fVhGH"
   },
   "source": [
    "## Начало работы с моделью: GPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q27OdWHss3vW"
   },
   "outputs": [],
   "source": [
    "!pip install -q accelerate --progress-bar off\n",
    "!pip install -q peft --progress-bar off\n",
    "!pip install -q bitsandbytes --progress-bar off\n",
    "!pip install -q transformers --progress-bar off\n",
    "!pip install -q trl --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXgqdVLws3sr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "from functools import partial\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          HfArgumentParser,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          EarlyStoppingCallback,\n",
    "                          pipeline,\n",
    "                          logging,\n",
    "                          set_seed)\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка отдельных элементов для Нейронной Сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HsiasFvys3qI"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Настраиваем метод квантизации модели с использованием bitsandbytes для ускорения обучения и вывода\n",
    "-  load_in_4bit                 <-- загрузка модель в режиме 4-битной точности\n",
    "-  bnb_4bit_use_double_quant    <-- вложенная квантизация для 4-битной модели\n",
    "-  bnb_4bit_quant_type          <-- тип данных для квантизации 4-битной модели\n",
    "-  bnb_4bit_compute_dtype       <-- тип данных для вычислений 4-битной модели\n",
    "'''\n",
    "\n",
    "def create_bnb_config(load_in_4bit, bnb_4bit_use_double_quant, bnb_4bit_quant_type, bnb_4bit_compute_dtype):\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                                    load_in_4bit = load_in_4bit,\n",
    "                                    bnb_4bit_use_double_quant = bnb_4bit_use_double_quant,\n",
    "                                    bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
    "                                    bnb_4bit_compute_dtype = bnb_4bit_compute_dtype,\n",
    "                                    )\n",
    "    return bnb_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры выгрузки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zzRvLZRNs3nk"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "''' \n",
    "Загружает модель и токенизатор модели.\n",
    "- model_name    <-- имя модели из библиотеки Hugging Face\n",
    "- bnb_config    <-- конфигурация Bitsandbytes\n",
    "'''\n",
    "def load_model(model_name, bnb_config):\n",
    "\n",
    "    # Получает количество доступных GPU и задает максимальный объем памяти\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    max_memory = f'{40960}MB'\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "     # Загружает модель\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "                                                model_name,\n",
    "                                                quantization_config = bnb_config,\n",
    "                                                device_map = 'auto',        # <-- автоматически распределяет модель на доступные ресурсы\n",
    "                                                max_memory = {i: max_memory for i in range(n_gpus)},\n",
    "                                                )\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Загружает токенизатор модели с использованием токена аутентификации пользователя\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token = False)\n",
    "\n",
    "     # Устанавливает токен для заполнения (padding) как токен конца предложения (EOS)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "puItQD47tlfl"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Параметры transformers:\n",
    "список опробованных обученных моделей из Hugging Face Hub для загрузки и тонкой настройки \n",
    "'''\n",
    "\n",
    "# model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_name = \"daryl149/llama-2-7b-chat-hf\"\n",
    "# model_name = \"OpenBuddy/openbuddy-llama2-13b-v8.1-fp16\"\n",
    "# model_name = \"OpenBuddy/openbuddy-llama-7b-v4-fp16\"\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"    # <-- модель, на которой на данный момент остановили выбор\n",
    "#model_name = \"rccmsu/ruadapt_llama2_7b_v0.1\"\n",
    "\n",
    "\n",
    "''' \n",
    "Параметры bitsandbytes\n",
    "* Bitsandbytes — это библиотека, которая предоставляет инструменты для эффективного использования моделей машинного обучения \n",
    "  с низкой точностью чисел, таких как 8-битные и 4-битные представления, что позволяет значительно уменьшить объем используемой \n",
    "  памяти и ускорить вычисления. Это особенно полезно при работе с крупными языковыми моделями, которые требуют значительных вычислительных ресурсов.\n",
    "'''\n",
    "\n",
    "# Активировать загрузку базовой модели с 4-битной точностью\n",
    "load_in_4bit = True\n",
    "\n",
    "# Активировать вложенную квантизацию для 4-битных базовых моделей (двойная квантизация)\n",
    "bnb_4bit_use_double_quant = True\n",
    "\n",
    "# Тип квантизации (fp4 или nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Тип данных для вычислений для 4-битных базовых моделей\n",
    "bnb_4bit_compute_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ml1I96uMvaKS"
   },
   "outputs": [],
   "source": [
    "# Загрузка модели из Hugging Face Hub с использованием имени модели и конфигурации bitsandbytes\n",
    "bnb_config = create_bnb_config(load_in_4bit, bnb_4bit_use_double_quant, bnb_4bit_quant_type, bnb_4bit_compute_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut9H6uP0s3lL"
   },
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(model_name, bnb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQsdgLh44yM-"
   },
   "source": [
    "### Загрузка датасета  \n",
    "Будем использовать заранее подготовленный датасет с инструкциями.  \n",
    "\n",
    "В данном случае это csv-таблица с 3 колонками:  \n",
    "\n",
    "* Инструкция  \n",
    "* Текст  \n",
    "* Класс  \n",
    "\n",
    "Мы будем использовать стандартный генератор датасета типа `csv` (потому что у нас файл CSV). Аналогично здесь мог бы быть файл JSON и типа датасет `json`. По умолчанию все записи относятся к разделению `train`, который мы получим с помощью параметра `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbcKeb4o8fAa"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files='work_data.csv', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLoaZvdTmIZT"
   },
   "outputs": [],
   "source": [
    "print(f'Number of prompts: {len(dataset)}')\n",
    "print(f'Column names are: {dataset.column_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6hxLRYZ7Fwd"
   },
   "source": [
    "Функция `load_dataset` преобразует файл CSV в словарь промтов. Мы можем просмотреть объекты, используя случайный индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulIcDOQVpun3"
   },
   "outputs": [],
   "source": [
    "dataset[randrange(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmOzs7Wj6NnR"
   },
   "source": [
    "### Создание шаблона промта  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KgLM5FR0mSP2"
   },
   "outputs": [],
   "source": [
    "''' Объединение шаблона с неизменными строками <=> Создание промта для модели на основе содержания промтов в датасте '''\n",
    "def create_prompt_formats(sample):\n",
    "\n",
    "    # Разделяет рубрики, предполагая, что они разделены точками с запятой\n",
    "    categories = sample['rubrics'].split(';')           \n",
    "    categories = [cat.strip() for cat in categories]    # <-- удаляет пробелы в начале и конце каждой рубрики\n",
    "    categories_str = ', '.join(categories)              # <-- объединяет рубрики в строку через запятую\n",
    "    categories = f\"Категории:\\n{categories_str}\"        # <-- формирует строку с заголовком \"Категории\"\n",
    "\n",
    "    # Формирует строки\n",
    "    rating = f\"Рейтинг:\\n{sample['rating']}\"\n",
    "    keywords = f\"Ключевые слова:\\n{sample['key_words']}\"\n",
    "    rewiev = f\"Отзыв:\\n{sample['text']}\"\n",
    "\n",
    "    # Создает список элементов шаблона подсказки\n",
    "    parts = [part for part in [categories, rating, keywords, rewiev] if part]\n",
    "\n",
    "    # Объединяет элементы шаблона подсказки в одну строку для создания шаблона подсказки\n",
    "    formatted_prompt = \"\\n\\n\".join(parts)\n",
    "\n",
    "    # Сохраняет отформатированный шаблон подсказки в новом ключе \"prompt\"\n",
    "    sample[\"prompt\"] = formatted_prompt\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iL1qmnMER4nH"
   },
   "outputs": [],
   "source": [
    "create_prompt_formats(dataset[randrange(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91ctsLt9G2Gc"
   },
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9M1e7HpDh2N"
   },
   "outputs": [],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V42Lk6Vx6y6P"
   },
   "source": [
    "### Получение максимальной длины последовательности предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "q6bAo-8nmtFn"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Извлечение максимальной длины токенов из конфигурации модели\n",
    "* Эта функция извлечет конфигурацию модели и попытается найти максимальную длину последовательности из одного из нескольких ключей конфигурации, \n",
    "  которые могут ее содержать. Если максимальная длина последовательности не найдена, по умолчанию она будет равна 1024. \n",
    "  Мы будем использовать максимальную длину последовательности во время предварительной обработки датасета, чтобы удалить записи, \n",
    "  которые превышают эту длину контекста, поскольку предварительно обученная модель не примет их.\n",
    "'''\n",
    "def get_max_length(model):\n",
    "\n",
    "    # Получает конфигурацию модели\n",
    "    conf = model.config\n",
    "    \n",
    "    # Инициализирует переменную \"max_length\" для хранения максимальной длины последовательности как пустую\n",
    "    max_length = None\n",
    "    \n",
    "    # Ищет максимальную длину последовательности в конфигурации модели и сохраняет её в \"max_length\", если найдена\n",
    "    for length_setting in ['n_positions', 'max_position_embeddings', 'seq_length']:\n",
    "        max_length = getattr(model.config, length_setting, None)\n",
    "        if max_length:\n",
    "            print(f\"Found max lenth: {max_length}\")\n",
    "            break\n",
    "        \n",
    "    # Устанавливает \"max_length\" в 1024 (значение по умолчанию), если максимальная длина последовательности не найдена в конфигурации модели\n",
    "    if not max_length:\n",
    "        max_length = 1024\n",
    "        print(f\"Using default max length: {max_length}\")\n",
    "        \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNs971cLTTTZ"
   },
   "source": [
    "#### Токенизирование батчей  \n",
    "\n",
    "Функция `preprocess_batch` будет токенизировать входящий (`batch`) используя  `tokenizer`.  \n",
    "\n",
    "Мы устанавливаем параметр максимальной длины последовательности  `max_length`, от которго будет зависеть паддинг либо обрезка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "C7vwFmJhmt6t"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Токенизация пакета данных\n",
    "- batch       <-- пакет данных\n",
    "- tokenizer   <-- токенизатор модели\n",
    "- max_length  <-- максимальное количество токенов, которое должен возвращать токенизатор\n",
    "'''\n",
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    return tokenizer(\n",
    "                    batch['prompt'],\n",
    "                    max_length = max_length,\n",
    "                    truncation = True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rsrRaiMDdIb"
   },
   "source": [
    "#### Предобработка датасета  \n",
    "\n",
    "1. Создание промтов через функцию `create_prompt_formats`.  \n",
    "\n",
    "2. Токенизирование батчей через функцию `preprocess_batch`, удаление исходных колонок (instruction, input, output, text).  \n",
    "\n",
    "3. Фильтрация итоговых промтов по максимальной длине в токенах.  \n",
    "\n",
    "4. Перемешивание датасета (shuffle) с инициализацией random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "S9UkOnqgmvlZ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Токенизирует набор данных для тонкой настройки.\n",
    "- tokenizer (AutoTokenizer) <-- токенизатор модели\n",
    "- param max_length (int)    <-- максимальное количество токенов, которое должен возвращать токенизатор\n",
    "- seed:                     <-- случайное зерно для воспроизводимости\n",
    "- dataset (str)             <-- набор данных с инструкциями\n",
    "'''\n",
    "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset: str):\n",
    "\n",
    "    # Добавляет шаблон подсказки к каждому образцу\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    dataset = dataset.map(create_prompt_formats)\n",
    "\n",
    "    # Применяет предобработку к каждому пакету набора данных и удаляет ненужные поля\n",
    "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
    "    dataset = dataset.map(\n",
    "                            _preprocessing_function,\n",
    "                            batched = True,\n",
    "                            remove_columns = ['address', 'name_ru', 'rating', 'rubrics', 'text','key_words'],\n",
    "                            )\n",
    "\n",
    "    # Фильтрует образцы, у которых \"input_ids\" превышает \"max_length\"\n",
    "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
    "\n",
    "    # Перемешивает набор данных\n",
    "    dataset = dataset.shuffle(seed = seed)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50XY9r6ssu-x"
   },
   "outputs": [],
   "source": [
    "# RD Для фиксации случайного элемента и возможности воссоздать \"эксперимент\"\n",
    "seed = 11111\n",
    "\n",
    "max_length = get_max_length(model)\n",
    "preprocessed_dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jepKTqUuIgID"
   },
   "source": [
    "Вот так выглядит теперь датасет, состоящий из токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-aACsuus0ps"
   },
   "outputs": [],
   "source": [
    "print(preprocessed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wN2y7yAIfN1"
   },
   "outputs": [],
   "source": [
    "print(preprocessed_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной этап обучения Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhI55wj7R9gd"
   },
   "source": [
    "### Создание конфигурации PEFT\n",
    "\n",
    "Подход PEFT позволяет тюнить небольшое количество дополнительных параметров модели, одновременно замораживая большинство параметров предварительно обученных LLM, значительно снижая затраты на вычисления и хранение. Это также помогает обеспечить переносимость: пользователи могут настраивать модели с помощью методов PEFT, чтобы получить LoRa-модули в размером в несколько МБ.\n",
    "\n",
    "\n",
    "Воспользуемся библиотекой `peft` из Hugging Face.\n",
    "\n",
    "Существует несколько методов PEFT. Мы будем использовать QLoRA, применяя класс `LoraConfig` из библиотеки  `peft`.\n",
    "\n",
    "QLoRA квантует модель в 4 бита, затем замораживает веса основной модели и добавляет две матрицы обучаемых мараметров. Во время тюнигна, QLoRA пробрасывает градиент через замороженную часть общей модели.\n",
    "\n",
    "Обновляются только веса LoRa-модуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "913uHanlnYef"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Создает конфигурацию для параметрически-эффективной тонкой настройки модели.\n",
    "- r                 <-- размерность внимания LoRA\n",
    "- lora_alpha        <-- параметр альфа для масштабирования LoRA\n",
    "- target_modules    <-- имена модулей, к которым будет применяться LoRA\n",
    "- lora_dropout      <-- вероятность применения Dropout в слоях LoRA\n",
    "- bias              <-- указывает, следует ли обучать параметры смещения (bias)\n",
    "- task_type         <-- тип задачи, для которой настраивается модель\n",
    "'''\n",
    "def create_peft_config(r, lora_alpha, target_modules, lora_dropout, bias, task_type):\n",
    "    config = LoraConfig(\n",
    "                        r = r,\n",
    "                        lora_alpha = lora_alpha,\n",
    "                        target_modules = target_modules,\n",
    "                        lora_dropout = lora_dropout,\n",
    "                        bias = bias,\n",
    "                        task_type = task_type,\n",
    "                        )\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVKxwcjPbBTq"
   },
   "source": [
    "#### Поиск модулей для LoRA\n",
    "\n",
    "Функция `find_all_linear_names` предназначен для поиска слоёв оригинальной сети, для которых будет применяться LoRa.\n",
    "\n",
    "\n",
    "Функция получает названия слоёв через `model.named_modules()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dg8pIUgMm_bX"
   },
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit             # <-- определяет класс 4-битных линейных модулей\n",
    "    lora_module_names = set()           # <-- создает множество для хранения имен модулей LoRA\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):                                             # <-- проверяет, является ли модуль экземпляром Linear4bit\n",
    "            names = name.split('.')                                             # <-- разделяет полное имя модуля на части\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])   # <-- добавляет имя модуля в множество\n",
    "\n",
    "    # Удаляет 'lm_head', если он есть в списке, так как обычно не применяется LoRA\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "        \n",
    "    print(f\"LoRA module names: {list(lora_module_names)}\")\n",
    "    return list(lora_module_names)      # <-- возвращает список имен модулей LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaaQtyB5b_Ag"
   },
   "source": [
    "#### Подсчёт обучаемых параметров\n",
    "\n",
    "Функция `print_trainable_parameters` предназначена для расчёта количества обучаемых параметров в `model.named_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "F6iEs6pVnCac"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model, use_4bit = False):\n",
    "    trainable_params = 0    # <-- переменная для подсчета количества обучаемых параметров\n",
    "    all_param = 0           # <-- переменная для подсчета общего количества параметров\n",
    "\n",
    "    for _, param in model.named_parameters():\n",
    "        # Получает количество элементов в параметре\n",
    "        num_params = param.numel()      \n",
    "        \n",
    "        # Использует альтернативное количество элементов, если доступно\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "        \n",
    "        all_param += num_params\n",
    "        \n",
    "        # Увеличивает количество обучаемых параметров, если они требуют градиента\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "\n",
    "    # Делит количество обучаемых параметров на 2, если используется 4-битная точность\n",
    "    if use_4bit:\n",
    "        trainable_params /= 2\n",
    "\n",
    "    print(f\"All Parameters: {all_param:,d} || \\\n",
    "            Trainable Parameters: {trainable_params:,d} || Trainable Parameters %: {100 * trainable_params / all_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOICPBjig9ri"
   },
   "source": [
    "### Fine-tuning предобученной модели\n",
    "\n",
    "Функция `fine_tune` оборачивает описанные выше модули и запускает их:\n",
    "\n",
    "1. Разрешить сохранение градиентов (gradient checkpointing) для уменьшения использования памяти во время тюнинга.  \n",
    "\n",
    "2. Использование функции `prepare_model_for_kbit_training` из PEFT для подготови модели к тюнингу.  \n",
    "\n",
    "3. Вызов `find_all_linear_names` для получения названий слоёв сети для применения LoRA.  \n",
    "\n",
    "4. Создание конфигурации LoRA через вызов функции `create_peft_config`.  \n",
    "\n",
    "5. Оборачивание базовой модели с Hugging Face model для тюнинга через PEFT путём вызова функции `get_peft_model`.  \n",
    "\n",
    "6. Печать обучаемых параметров.  \n",
    "\n",
    "\n",
    "Для обучения мы инициализируем объект `Trainer()` внутри функции `fine_tune`, который требует:\n",
    "\n",
    "\n",
    "* `per_device_train_batch_size` — размер батча на обучении.\n",
    "\n",
    "* `gradient_accumulation_steps` — количество шагов, для которых необходимо накопить градиенты перед выполнением обратного прохода.\n",
    "\n",
    "* `warmup_steps` — количество шагов линейного увеличения скорости обучения от 0 до `learning_rate`.  \n",
    "\n",
    "* `max_steps`: количество шагов обучения.  \n",
    "\n",
    "* `learning_rate`: начальный  learning rate для Adam.  \n",
    "\n",
    "* `fp16`: использовать ли 16-bit (mixed) обучение вместо  32-bit.  \n",
    "\n",
    "* `logging_steps`: количество шагов между двумя логированиями.  \n",
    "\n",
    "* `output_dir`: папка для сохранения логов и модели.  \n",
    "\n",
    "* `optim`: оптимизатор для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tCbnhnxtnhvh"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Подготовка и выполнение тонкой настройки предварительно обученной модели.\n",
    "- model        <-- предварительно обученная модель от Hugging Face\n",
    "- tokenizer    <-- токенизатор для модели\n",
    "- dataset      <-- предварительно обработанный набор данных для обучения\n",
    "'''\n",
    "def fine_tune(model, tokenizer, dataset, lora_r, lora_alpha, lora_dropout, bias,\n",
    "                task_type, per_device_train_batch_size, gradient_accumulation_steps,\n",
    "                    warmup_steps, max_steps, learning_rate, fp16, logging_steps, output_dir, optim):\n",
    "\n",
    "    # Включает градиентное контрольное сохранение для уменьшения использования памяти при тонкой настройке\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    # Подготавливает модель для обучения с использованием квантизации\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # Получает имена модулей LoRA\n",
    "    target_modules = find_all_linear_names(model)\n",
    "\n",
    "    # Создает конфигурацию PEFT для этих модулей и оборачивает модель в PEFT\n",
    "    peft_config = create_peft_config(lora_r, lora_alpha, target_modules, lora_dropout, bias, task_type)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    # Выводит информацию о проценте обучаемых параметров\n",
    "    print_trainable_parameters(model)\n",
    "\n",
    "    # Параметры обучения\n",
    "    trainer = Trainer(\n",
    "                        model = model,\n",
    "                        train_dataset = dataset,\n",
    "                        args = TrainingArguments(\n",
    "                                                per_device_train_batch_size = per_device_train_batch_size,\n",
    "                                                gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "                                                warmup_steps = warmup_steps,\n",
    "                                                max_steps = max_steps,\n",
    "                                                learning_rate = learning_rate,\n",
    "                                                fp16 = fp16,\n",
    "                                                logging_steps = logging_steps,\n",
    "                                                output_dir = output_dir,\n",
    "                                                optim = optim,\n",
    "                                                report_to='tensorboard'                         # <-- логирование результатов в TensorBoard\n",
    "                                                ),\n",
    "                        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False) # <--  # подготовка данных для языкового моделирования без маскирования\n",
    "                        )\n",
    "\n",
    "    # Отключает использование кэша\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    do_train = True\n",
    "\n",
    "    # Запускает обучение и логирует метрики\n",
    "    print(\"Training...\")\n",
    "\n",
    "    if do_train:\n",
    "        train_result = trainer.train()\n",
    "        metrics = train_result.metrics\n",
    "        trainer.log_metrics(\"train\", metrics)   # <-- логирует метрики обучения\n",
    "        trainer.save_metrics(\"train\", metrics)  # <-- сохраняет метрики обучения\n",
    "        trainer.save_state()                    # <-- сохраняет состояние обучения\n",
    "        print(metrics)\n",
    "\n",
    "    # Сохраняет последнюю контрольную точку модели\n",
    "    print(\"Saving last checkpoint of the model...\")\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "\n",
    "    # Освобождает память для объединения весов\n",
    "    del model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()    # <-- ВАЖНАЯ ШТУКА: очищает кэш GPU!!!!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP3k_qjEvvSF"
   },
   "source": [
    "### Использование парамертов QLoRa для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FxC2aY8eUzH7"
   },
   "outputs": [],
   "source": [
    "# Размерность внимания LoRA\n",
    "lora_r = 16\n",
    "\n",
    "# Параметр альфа для масштабирования LoRA\n",
    "lora_alpha = 64\n",
    "\n",
    "# Вероятность dropout для слоев LoRA\n",
    "lora_dropout = 0.1\n",
    "\n",
    "# Смещение\n",
    "bias = \"none\"\n",
    "\n",
    "# Тип задачи\n",
    "task_type = \"CAUSAL_LM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nnfOKEvipXLG"
   },
   "outputs": [],
   "source": [
    "# Директория для хранения предсказаний модели и контрольных точек\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Размер пакета данных на одну GPU для обучения (собственно, в данном случае одна GPU и есть)\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "# Количество шагов обновления для накопления градиентов\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Начальная скорость обучения (оптимизатор AdamW)\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Используемый оптимизатор\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Количество шагов обучения (переопределяет num_train_epochs)\n",
    "max_steps = 40000 #0\n",
    "\n",
    "# Линейное увеличение шагов от 0 до learning_rate\n",
    "warmup_steps = 100\n",
    "\n",
    "# Включить обучение с использованием fp16\n",
    "fp16 = True\n",
    "\n",
    "# Логирование каждые X шагов обновления\n",
    "logging_steps = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRJZ6L7qpPIM"
   },
   "outputs": [],
   "source": [
    "fine_tune(model,\n",
    "            tokenizer,\n",
    "            preprocessed_dataset,\n",
    "            lora_r,\n",
    "            lora_alpha,\n",
    "            lora_dropout,\n",
    "            bias,\n",
    "            task_type,\n",
    "            per_device_train_batch_size,\n",
    "            gradient_accumulation_steps,\n",
    "            warmup_steps,\n",
    "            max_steps,\n",
    "            learning_rate,\n",
    "            fp16,\n",
    "            logging_steps,\n",
    "            output_dir,\n",
    "            optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты и тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pront\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Сразу указываем, что девайс - GPU\n",
    "device = 'cuda'\n",
    "\n",
    "# Укажите путь к контрольной точке с LoRA-адаптерами\n",
    "checkpoint_path = \"results/checkpoint-40000\"\n",
    "\n",
    "# Загрузка базовой модели\n",
    "base_model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "\n",
    "# Загрузка конфигурации LoRA-адаптера\n",
    "peft_config = PeftConfig.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Объединение базовой модели с LoRA-адаптером\n",
    "model = PeftModel.from_pretrained(base_model, checkpoint_path)\n",
    "\n",
    "# Перемещение модели на GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             address             name_ru  \\\n",
      "0  Екатеринбург, ул. Московская / ул. Волгоградск...  московский квартал   \n",
      "1  Московская область, Электросталь, проспект Лен...   продукты ермолино   \n",
      "2  Краснодар, Прикубанский внутригородской округ,...             limefit   \n",
      "3   Санкт-Петербург, проспект Энгельса, 111, корп. 1        snow-express   \n",
      "4                  Тверь, Волоколамский проспект, 39  студия beauty brow   \n",
      "\n",
      "   rating                                            rubrics  \\\n",
      "0     3.0                                     жилой комплекс   \n",
      "1     5.0  магазин продуктов;продукты глубокой заморозки;...   \n",
      "2     1.0                                        фитнес-клуб   \n",
      "3     4.0        пункт проката;прокат велосипедов;сапсёрфинг   \n",
      "4     5.0  салон красоты;визажисты, стилисты;салон бровей...   \n",
      "\n",
      "                                                text  \\\n",
      "0  московский квартал 2. шумно летом по ночам дик...   \n",
      "1  замечательная сеть магазинов в общем, хороший ...   \n",
      "2  не знаю смутят ли когото данные правила, но я ...   \n",
      "3  хорошие условия аренды. дружелюбный персонал. ...   \n",
      "4  топ мастер ангелина топ во всех смыслах ) немн...   \n",
      "\n",
      "                      key_words  \n",
      "0              16, обычно, окна  \n",
      "1     ассортимент, высоте, сеть  \n",
      "2  говорят, доверенности, номер  \n",
      "3       аренды, ботинки, бывают  \n",
      "4            ангелина, всё, топ  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Обработанные ранее данные\n",
    "data_path = 'work_data.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Просмотр первых 5 строк\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение значений в столбце rubrics\n",
    "data['rubrics_split'] = data['rubrics'].str.split(';')\n",
    "\n",
    "# Уникальные значения категорий\n",
    "unique_rubrics = pd.Series([rubric for sublist in data['rubrics_split'].dropna() for rubric in sublist]).unique()\n",
    "# print('Уникальные рубрики:')\n",
    "# for rubric in unique_rubrics:\n",
    "#     print('-', rubric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальные значения рейтингов\n",
    "ratings = data['rating'].unique() \n",
    "# print('Уникальные рейтинги:', ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем цифры и извлекаем уникальные ключевые слова\n",
    "keywords_split = data['key_words'].str.split(',').explode() \n",
    "  \n",
    "# Фильтруем ключевые слова без цифр\n",
    "keywords_no_digits = keywords_split[~keywords_split.str.contains(r'\\d')].unique()\n",
    "# print('Уникальные ключевые слова без цифр:')\n",
    "# for keyword in keywords_no_digits:\n",
    "#     print('-', keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция генерации отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_review(category, rating, keywords, max_length=50, temperature=1, top_k=100000, top_p=1.5):\n",
    "    \n",
    "    prompt = f\"Категория: {category}\\nРейтинг: {rating}\\nКлючевые слова: {keywords}\\nОтзыв:\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "                                inputs.to(device),\n",
    "                                max_length=inputs.shape[1] + max_length,\n",
    "                                temperature=temperature,\n",
    "                                top_k=top_k,\n",
    "                                top_p=top_p,\n",
    "                                do_sample=True,\n",
    "                                num_return_sequences=1,\n",
    "                                pad_token_id=tokenizer.eos_token_id\n",
    "                                )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Извлечение только текста отзыва\n",
    "    review = generated_text.split('Отзыв:')[-1].strip()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция рандомной генерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# Функция для генерации случайных значений\n",
    "def generate_random_combinations(repeats=20, seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(repeats):\n",
    "        rubric = np.random.choice(unique_rubrics)\n",
    "        rating = int(np.random.choice(ratings))\n",
    "        keyword = np.random.choice(keywords_no_digits)\n",
    "        \n",
    "        print(f\"Рубрика: {rubric}, Рейтинг: {rating}, Ключевое слово: {keyword}\")\n",
    "        review = generate_review(rubric, rating, keyword)\n",
    "        print(f\"Сгенерированный отзыв: {review}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Непосредственно сама генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рубрика: нефтегазовая компания, Рейтинг: 2, Ключевое слово:  лучшую\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "c:\\Users\\pront\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный отзыв: работали хорошую компанию. и многое, многое, имеет смысл видеть во взглядах многих бизнесменов. всем советую и нашу компанию. я бы сказала, что нам самая лучшая компания в районе. с удовольствием оценю результат труда, он есть. цены и\n",
      "\n",
      "Рубрика: животноводческое хозяйство, Рейтинг: 2, Ключевое слово:  перенасыщение\n",
      "Сгенерированный отзыв: как хотелось бы отметить коровник на биговской что находится в жилом доме на улице Тургенева. правда маловажную трансформацию произвели при уплотнении зерновых 2: коровник не рассчитан на площадь вместимости. не привыкли мы к\n",
      "\n",
      "Рубрика: саморегулируемая организация, Рейтинг: 5, Ключевое слово:  избранных\n",
      "Сгенерированный отзыв: давно замечательное место,очень удобно выбрать между thousands разных. выбор оттисков до списков компаний,вопросы которые у нас возникают во время выбора,решение которых мы решаем.сегодня понимание гражданина появившемся в новом месте\n",
      "\n",
      "Рубрика: кабельное телевидение, Рейтинг: 0, Ключевое слово:  константу\n",
      "Сгенерированный отзыв: неплохая компания, работал и не раз сталкиваюсь с этим, качество отличное, есть даже поддержка, все устраивает, здорово что есть свой провайдер и определять качество в облаке удобно, а не в пробках, так что подобные пё\n",
      "\n",
      "Рубрика: столовая, Рейтинг: 3, Ключевое слово:  бир\n",
      "Сгенерированный отзыв: отличный стол. очень уютно и много народа. персонал вежливый, могут помочь и проконсультировать по доставке. отдельно отмечу большую очередь к холодильнику, но он есть. внимательность и профессионализм персонала. за невысокую цену приемлемо\n",
      "\n",
      "Рубрика: ветеринарная клиника, Рейтинг: 4, Ключевое слово:  подсела\n",
      "Сгенерированный отзыв: кусная капуста и клевая еда. самый лучший персонал в этом районе. у них есть свои клининги, своя лаборатория и хороший ветеринарный персонал. на кпк не сдыхаешь. цены хорошие, приятно работать. клиника\n",
      "\n",
      "Рубрика: платные базы данных, Рейтинг: 2, Ключевое слово:  сарае\n",
      "Сгенерированный отзыв: небольшой будний день базар задний дворик к сараю но час пока пробки!!! парилка саня джанфар! украина! надёжно. никурий сумаид. беглой заметке вроде притоны. автомат с па\n",
      "\n",
      "Рубрика: текстильное оборудование, Рейтинг: 2, Ключевое слово:  лучшай\n",
      "Сгенерированный отзыв: просто крабовые палочки, лучшай вкусное смешано в момент насыщения, красота. прям из творожных кубиков! хорошо, если в комплекте с набором роллов хоть один роллистка и ролл с плотным\n",
      "\n",
      "Рубрика: развлекательный центр, Рейтинг: 0, Ключевое слово: воздуходувку\n",
      "Сгенерированный отзыв: персонал адекватный, проще отдать. ходить очень удобно. музей. Пушкинский дворец. библиотека. интернет везде. дворики, скверы. развлекательный центр. и вообще чистый воздух. водонапорная башня. фонтан. много ресторанов\n",
      "\n",
      "Рубрика: магазин кулинарии, Рейтинг: 5, Ключевое слово:  франшиза\n",
      "Сгенерированный отзыв: хороший выбор ресторанов, есть франшиза с хорошей франшизой. во всей сети есть реализброл и урло хлеба, мясо, рыба. в наличии, есть егпрб и норильск. персонал трудолюбивый,\n",
      "\n",
      "Рубрика: военная, кадетская школа, Рейтинг: 5, Ключевое слово: благожелательное\n",
      "Сгенерированный отзыв: нам очень понравилось. отличная школа. отношение хорошее...хороший детский сад для детей почти самой младшей группы.(ну скажите в саду. дети нашли там хорошие точки учебки для занятия. конечно,зарплата есть!). ребята молодцы! огромное спасибо каждому педаг\n",
      "\n",
      "Рубрика: средства гигиены, Рейтинг: 1, Ключевое слово:  нюансами\n",
      "Сгенерированный отзыв: сделана ради красоты и здоровья. мой персональный приветливый доктор. из минусов глажка. так как у меня только пар, я жутко простыла. поэтому блеск для губ. пока нет никаких гарантий. вспомнилась с детства, когда\n",
      "\n",
      "Рубрика: магазин электроники, Рейтинг: 5, Ключевое слово:  интересующимся\n"
     ]
    }
   ],
   "source": [
    "generate_random_combinations()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LLM 02L - LoRA with PEFT",
   "widgets": {}
  },
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
